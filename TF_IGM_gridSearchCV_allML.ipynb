{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import operator\n",
    "import matplotlib.pyplot as plt \n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "import glob, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('/home/oem/jin/python/after_prepro10yr.csv', encoding=\"CP949\")\n",
    "\n",
    "\n",
    "print(len(data.iloc[:,0]))\n",
    "\n",
    "\n",
    "\n",
    "X = data.iloc[:,1].values\n",
    "y = data.iloc[:,2].values\n",
    "print(X)\n",
    "print(y)\n",
    "#y = data[2]\n",
    "\n",
    "\n",
    "x1 = []\n",
    "\n",
    "for sre in X:\n",
    "    text = sre.rstrip()\n",
    "    \n",
    "    x1.append(text)\n",
    "    \n",
    "\n",
    "#print(len(x1))\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=8000)\n",
    "# 그에 맞게 단어 인덱스를 구축\n",
    "tokenizer.fit_on_texts(x1)\n",
    "\n",
    "# 문자열을 인덱스의 리스트로 변환\n",
    "sequences = tokenizer.texts_to_sequences(x1)\n",
    "index = tokenizer.word_index\n",
    "index_word = tokenizer.index_word\n",
    "print(index[\"미세먼지\"])\n",
    "print(index_word[1])\n",
    "\n",
    "\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences(X)\n",
    "dataset = []\n",
    "labels = y\n",
    "num_labels = len(labels)\n",
    "for i,sentence in enumerate(encoded):\n",
    "    dataset.append((sentence,y[i]))\n",
    "#print(dataset)\n",
    "from collections import Counter\n",
    "counter_list = []\n",
    "for label in labels:\n",
    "    label_dic = list(filter(lambda x: x[1]==label, dataset))\n",
    "    label_dic = [e[0] for e in label_dic]\n",
    "    label_dic = [e for element in label_dic for e in element]\n",
    "    label_dic = Counter(label_dic)\n",
    "    counter_list.append(label_dic)\n",
    "\n",
    "\n",
    "\n",
    "vocab = 8000\n",
    "\n",
    "word_freq_dic = {}   ###### 문서별 단어 빈도수 계산 하기 \n",
    "for word_idx in range(1,vocab):\n",
    "    word_freq = []\n",
    "    #print(word_idx)\n",
    "    for i in range(len(labels)):\n",
    "        word_freq.append((counter_list[i][word_idx]))\n",
    "    word_freq_dic[word_idx] = word_freq\n",
    "        \n",
    "\n",
    "\n",
    "igm_dict = {}\n",
    "wg_dict = {}\n",
    "alpha = 7\n",
    "for word_idx in range(1,vocab):\n",
    "    sorted_list = sorted(word_freq_dic[word_idx],reverse=True)\n",
    "    denom = 0\n",
    "    for i in range(num_labels):\n",
    "        denom += sorted_list[i]*(i+1)\n",
    "        \n",
    "        \n",
    "    igm_dict[word_idx] = sorted_list[0]/denom\n",
    "    wg_dict[word_idx] = 1+(alpha*igm_dict[word_idx])\n",
    "    \n",
    "\n",
    "\n",
    "idx_to_count = [e[0] for e in dataset]\n",
    "idx_to_count = Counter([e for element in idx_to_count for e in element])\n",
    "tf_term = {}\n",
    "for word_idx in range(1,vocab):\n",
    "    tf_term[word_idx] =  idx_to_count[word_idx] / vocab\n",
    "    \n",
    "tf_igm = {}\n",
    "for word_idx in range(1,vocab):\n",
    "    tf_igm[word_idx] = tf_term[word_idx]*wg_dict[word_idx]\n",
    "    \n",
    "\n",
    "    \n",
    "lst = np.zeros((44491, 8000))\n",
    "\n",
    "\n",
    "to = 0\n",
    "for line in encoded:\n",
    "    for x in line:\n",
    "        \n",
    "        result = tf_igm[x]\n",
    "        \n",
    "        lst[to][x] = result\n",
    "\n",
    "    to += 1\n",
    "    \n",
    "\n",
    "decoding = pad_sequences(lst, padding='post', dtype='float32')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(decoding,y, test_size=0.25, shuffle=True, random_state=25, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### deault ML capplication #######\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "LogReg = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "model = [svc, LogReg, nb, rf, xgb]\n",
    "\n",
    "\n",
    "for m in model:\n",
    "    m.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "for m in model:\n",
    "    pred = m.predict(X_test)\n",
    "    print('Acc for model', accuracy_score(y_test,pred))\n",
    "    print('Confusion Matrix for model', confusion_matrix(y_test, pred))\n",
    "    print('F1-score for model', classification_report(y_test, pred))\n",
    "    \n",
    "##### end of the defulat ML application ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### gridsearchCV for SVM classifer \n",
    "\n",
    "\n",
    "svm_tf_igm = open('tf_igm_svm.txt', 'w')\n",
    "\n",
    "parameters = [{\"kernel\":[\"rbf\"], \"gamma\":[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05,0.1, 1, 5, 10, 20, 50, 100, 200, 500, 1000], \"C\":[0.001, 0.005, 0.01, 0.1, 1, 5, 10, 20, 30, 40, 50, 100, 200, 500, 700, 1000], \"degree\":[1, 2, 3, 4, 5]}]\n",
    "\n",
    "#scores = [\"precision\", \"recall_macro\"]\n",
    "scores = [\"accuracy\"]\n",
    "\n",
    "print(\"# tuning hypter parmeter for %s\" % score)\n",
    "print()\n",
    "    \n",
    "clf_svm = GridSearchCV(SVC(random_state = 2), parameters, scoring=scores, verbose = 3, n_jobs=6, cv=5)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "    \n",
    "print(\"best parameters st found on devleopment set:\")\n",
    "print()\n",
    "print(clf_svm.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "means = clf_svm.cv_results_[\"mean_test_score\"]\n",
    "stds = clf_svm.cv_results_[\"std_test_score\"]\n",
    "    \n",
    "\n",
    "for mean, std, params in tqdm(zip(means, stds, clf_svm.cv_results_[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params), file=svm_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Detailed classifciaiton reprot:\")\n",
    "print()\n",
    "print(\"the model is trained on the full development set.\")\n",
    "print(\"the scores are computed on the full developement set\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf_svm.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), file=svm_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "svm_tf_igm.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### end gridsearchCV for SVM classifer #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### gridsearchCV for naive_bayes classifer #######\n",
    "\n",
    "rb_igm_tf = open('tf_igm_rb.txt', 'w')\n",
    "\n",
    "\n",
    "parameters = [{\"alpha\": [00.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 6, 7, 8, 9, 10, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500], \"fit_prior\": [\"True\", \"False\"]}]\n",
    "# scores = [\"precision\", \"recall_macro\"]\n",
    "#scores = [\"accuracy\"]\n",
    "scores = make_scorer(accuracy_score)\n",
    "\n",
    "print(\"# tuning hypter parmeter for %s\" % scores)\n",
    "print()\n",
    "\n",
    "clf_rb = GridSearchCV(rb, parameters, scoring=scores, verbose=3, n_jobs=6, cv=5)\n",
    "clf_rb.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters st found on devleopment set:\")\n",
    "print()\n",
    "print(clf_rb.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "means = clf_rb.cv_results_[\"mean_test_score\"]\n",
    "stds = clf_rb.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in tqdm(zip(means, stds, clf_rb.cv_results_[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params), file=rb_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Detailed classifciaiton reprot:\")\n",
    "print()\n",
    "print(\"the model is trained on the full development set.\")\n",
    "print(\"the scores are computed on the full developement set\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf_rb.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), file=rb_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "svm_tf_igm.close()\n",
    "\n",
    "\n",
    "###### end gridsearchCV for naive_bayes classifer #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### gridsearchCV for ramdon forest classifer #######\n",
    "\n",
    "rf_igm_tf = open('tf_igm_rf.txt', 'w')\n",
    "\n",
    "rf = RandomForestClassifier(random_state=2017)\n",
    "parameters = [{\"n_estimators\": [4, 6, 8, 10, 15, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500, 600, 800, 1000], \"max_features\": ['sqrt', 'log2'], \"max_depth\": [4, 6, 8, 10, 12, 16, 18, 20, 22, 24, 26, 28, 30], 'criterion': ['gini', 'entropy', 'log_loss']}]\n",
    "scores = make_scorer(accuracy_score)\n",
    "\n",
    "print(\"# tuning hypter parmeter for %s\" % scores)\n",
    "print()\n",
    "\n",
    "clf_rf = GridSearchCV(rf, parameters, scoring=scores, verbose=3, n_jobs=6, cv=5)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters st found on devleopment set:\")\n",
    "print()\n",
    "print(clf_rf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "means = clf_rf.cv_results_[\"mean_test_score\"]\n",
    "stds = clf_rf.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in tqdm(zip(means, stds, clf_rf.cv_results_[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params), file=rf_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Detailed classifciaiton reprot:\")\n",
    "print()\n",
    "print(\"the model is trained on the full development set.\")\n",
    "print(\"the scores are computed on the full developement set\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf_rb.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), file=rf_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "rf_tf_igm.close()\n",
    "\n",
    "\n",
    "\n",
    "##### end gridsearchCV for ramdon forest classifer #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### gridsearchCV for Logistic regression classifer #######\n",
    "\n",
    "\n",
    "lr_tf_igm = open('tf_igm_lr.txt', 'w')\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial', class_weight='balanced', random_state=2017)\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100, 200]\n",
    "max_i = [20, 50, 100, 200, 500, 1000]\n",
    "parameters = [{\"penalty\": [\"l1\"], \"C\": c_range, \"solver\": [\"saga\"], 'max_iter': max_i},\n",
    "              {\"penalty\": [\"l2\"], \"C\": c_range, \"solver\": [\"saga\"], 'max_iter': max_i},\n",
    "              {\"penalty\": [\"elasticnet\"], \"C\": c_range, \"solver\": [\"saga\"], 'max_iter': max_i, 'l1_ratio': [0.5]}]\n",
    "\n",
    "scores = make_scorer(accuracy_score)\n",
    "\n",
    "print(\"# tuning hypter parmeter for %s\" % scores)\n",
    "print()\n",
    "\n",
    "clf_lr = GridSearchCV(lr, parameters, scoring=scores, verbose=3, n_jobs=6, cv=5)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters st found on devleopment set:\")\n",
    "print()\n",
    "print(clf_lr.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "means = clf_lr.cv_results_[\"mean_test_score\"]\n",
    "stds = clf_lr.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in tqdm(zip(means, stds, clf_lr.cv_results_[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params), file=lr_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Detailed classifciaiton reprot:\")\n",
    "print()\n",
    "print(\"the model is trained on the full development set.\")\n",
    "print(\"the scores are computed on the full developement set\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf_lr.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), file=lr_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "lr_tf_igm.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### end gridsearchCV for Logistic regression classifer #######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### gridsearchCV for XGBoost classifer #######\n",
    "\n",
    "\n",
    "xgb_tf_igm = open('tf_igm_xgb.txt', 'w')\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(random_state=2017)\n",
    "parameters = [{\"max_depth\":[2, 4, 8, 12, 16, 18, 22, 26], \"gamma\":[0.1, 1, 2, 4, 8, 12, 16, 20, 24], \"colsample_bytree\": [0.1, 0.2, 0.4, 0.6],\n",
    "               \"min_child_weight\":[1, 2, 4, 8, 10], \"subsample\":[0.1, 0.5, 0.7, 1]}]\n",
    "# scores = [\"precision\", \"recall_macro\"]\n",
    "#scores = [\"accuracy\"]\n",
    "scores = make_scorer(accuracy_score)\n",
    "\n",
    "print(\"# tuning hypter parmeter for %s\" % scores)\n",
    "print()\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, parameters, scoring=scores, verbose=3, n_jobs=6, cv=3)\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters st found on devleopment set:\")\n",
    "print()\n",
    "print(clf_xgb.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "means = clf_xgb.cv_results_[\"mean_test_score\"]\n",
    "stds = clf_xgb.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in tqdm(zip(means, stds, clf_xgb.cv_results_[\"params\"])):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params), file=xgb_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Detailed classifciaiton reprot:\")\n",
    "print()\n",
    "print(\"the model is trained on the full development set.\")\n",
    "print(\"the scores are computed on the full developement set\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf_xgb.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), file=xgb_tf_igm)\n",
    "\n",
    "print()\n",
    "\n",
    "xgb_tf_igm.close()\n",
    "\n",
    "\n",
    "##### end gridsearchCV for XGBoost classifer #######\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
